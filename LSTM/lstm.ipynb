{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install gensim==4.3.2 --quiet"
      ],
      "metadata": {
        "id": "COZyYSKir64r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall \"scipy==1.10.1\" \"numpy==1.26.4\" \"gensim==4.3.2\" --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcba3F4bstXz",
        "outputId": "6934f7c8-e0b8-4baf-9045-fd0c247d1d28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eEKXDU5lrP2I"
      },
      "outputs": [],
      "source": [
        "# ==================================================\n",
        "# 0. INSTALL & IMPORT LIBRARY\n",
        "# ==================================================\n",
        "\n",
        "# Fix for gensim/scipy incompatibility: ensure compatible scipy version is installed.\n",
        "# This requires a runtime restart after execution for the changes to take full effect.\n",
        "!pip install scipy==1.11.4 --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import optimizers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 1. BACA DATA\n",
        "# ==================================================\n",
        "# GANTI path & nama kolom sesuai dataset-mu\n",
        "# Misal: kolom teks = 'tweet', label = 'label' (0 = non-sarkas, 1 = sarkas)\n",
        "\n",
        "df = pd.read_csv(\"/content/cleaned_for_training_final (3).csv\")\n",
        "\n",
        "print(\"Contoh 5 data teratas:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDistribusi label:\")\n",
        "print(df['label'].value_counts())\n",
        "print(\"\\nPersentase label:\")\n",
        "print((df['label'].value_counts(normalize=True) * 100).round(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgQ0EjNqrld2",
        "outputId": "85a9bf07-90a5-4982-d3b7-b3e046a581c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contoh 5 data teratas:\n",
            "                                           full_text  \\\n",
            "0   jangan terkecoh berita korup ingat #KaburAjaDulu   \n",
            "1  Berharap Indonesia Emas tp pra-syarat menjadi ...   \n",
            "2  wdyt #KaburAjaDulu ke kamboja jd admin judol l...   \n",
            "3  Liat kakak gw tinggal di Belanda makmur2 aj hi...   \n",
            "4  Culik aku kuliner sebelum berangkat lagi ke ne...   \n",
            "\n",
            "                                          clean_text  label  \n",
            "0  jangan kecoh berita korupsi ingat kabur saja dulu      0  \n",
            "1  harap indonesia emas tapi pra syarat jadi indo...      1  \n",
            "2  wdyt kabur saja dulu ke kamboja jadi admin jud...      0  \n",
            "3  lihat kakak saya tinggal di belanda makmur saj...      0  \n",
            "4  culik aku kuliner belum berangkat lagi ke nega...      1  \n",
            "\n",
            "Distribusi label:\n",
            "label\n",
            "0    4374\n",
            "1    2804\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Persentase label:\n",
            "label\n",
            "0    60.94\n",
            "1    39.06\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# SPLIT DATA 70:15:15\n",
        "# ==================================================\n",
        "\n",
        "# Train = 70%, sisanya 30%\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    df[\"clean_text\"].values,\n",
        "    df[\"label\"].values,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"].values\n",
        ")\n",
        "\n",
        "# Dari sisa 30% → bagi menjadi val 15% & test 15%\n",
        "# Artinya val = 0.5 * temp dan test = 0.5 * temp\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Jumlah train :\", len(X_train), f\"({(len(X_train)/len(df)*100):.2f} %)\")\n",
        "print(\"Jumlah val   :\", len(X_val),   f\"({(len(X_val)/len(df)*100):.2f} %)\")\n",
        "print(\"Jumlah test  :\", len(X_test),  f\"({(len(X_test)/len(df)*100):.2f} %)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKXZhhazrr1N",
        "outputId": "acdfeaf1-8233-4e27-9cbc-1b3f9521ea7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah train : 5024 (69.99 %)\n",
            "Jumlah val   : 1077 (15.00 %)\n",
            "Jumlah test  : 1077 (15.00 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "# Membuat TaggedDocument dari data TRAIN saja\n",
        "train_tagged = [\n",
        "    TaggedDocument(words=text.split(), tags=[f\"train_{i}\"])\n",
        "    for i, text in enumerate(X_train)\n",
        "]\n",
        "\n",
        "len(train_tagged), train_tagged[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TaYWkcxsmNj",
        "outputId": "974634da-0032-4d0e-8b8b-694c9cd886c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5024,\n",
              " TaggedDocument(words=['besok', 'senin', 'kabur', 'saja', 'dulu'], tags=['train_0']))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VECTOR_SIZE = 300   # dimensi embedding dokumen\n",
        "EPOCHS_D2V = 40\n",
        "\n",
        "d2v_model = Doc2Vec(\n",
        "    vector_size=VECTOR_SIZE,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4,\n",
        "    dm=1,        # 1 = Distributed Memory (doc2vec DM), 0 = DBOW\n",
        "    epochs=EPOCHS_D2V\n",
        ")\n",
        "\n",
        "d2v_model.build_vocab(train_tagged)\n",
        "print(\"Jumlah kata di vocab:\", len(d2v_model.wv))\n",
        "\n",
        "d2v_model.train(\n",
        "    train_tagged,\n",
        "    total_examples=d2v_model.corpus_count,\n",
        "    epochs=d2v_model.epochs\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "_5g7Xi6ktJr6",
        "outputId": "f3501368-f2dd-4c43-f8fd-24d1c84a76d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Doc2Vec' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2690057492.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEPOCHS_D2V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m d2v_model = Doc2Vec(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVECTOR_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Doc2Vec' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "babcc3c0",
        "outputId": "dbbe1390-67fc-4fd5-c94a-edd6fd89cb45"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "VECTOR_SIZE = 300   # dimensi embedding dokumen\n",
        "EPOCHS_D2V = 40\n",
        "\n",
        "d2v_model = Doc2Vec(\n",
        "    vector_size=VECTOR_SIZE,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4,\n",
        "    dm=1,        # 1 = Distributed Memory (doc2vec DM), 0 = DBOW\n",
        "    epochs=EPOCHS_D2V\n",
        ")\n",
        "\n",
        "d2v_model.build_vocab(train_tagged)\n",
        "print(\"Jumlah kata di vocab:\", len(d2v_model.wv))\n",
        "\n",
        "d2v_model.train(\n",
        "    train_tagged,\n",
        "    total_examples=d2v_model.corpus_count,\n",
        "    epochs=d2v_model.epochs\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah kata di vocab: 3623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_doc_vectors(model, texts):\n",
        "    vectors = []\n",
        "    for text in texts:\n",
        "        tokens = text.split()\n",
        "        vec = model.infer_vector(tokens)\n",
        "        vectors.append(vec)\n",
        "    return np.array(vectors)\n",
        "\n",
        "X_train_vec = get_doc_vectors(d2v_model, X_train)\n",
        "X_val_vec   = get_doc_vectors(d2v_model, X_val)\n",
        "X_test_vec  = get_doc_vectors(d2v_model, X_test)\n",
        "\n",
        "print(\"Shape X_train_vec:\", X_train_vec.shape)\n",
        "print(\"Shape X_val_vec  :\", X_val_vec.shape)\n",
        "print(\"Shape X_test_vec :\", X_test_vec.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr0rnsZNtZoX",
        "outputId": "66752a7f-8aa0-4717-baad-23f9e7d547cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train_vec: (5024, 300)\n",
            "Shape X_val_vec  : (1077, 300)\n",
            "Shape X_test_vec : (1077, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 7A. MODEL DENSE (MLP) UNTUK KLASIFIKASI\n",
        "# ==================================================\n",
        "model_dense = Sequential()\n",
        "model_dense.add(Dense(128, activation=\"relu\", input_shape=(VECTOR_SIZE,)))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(Dense(64, activation=\"relu\"))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model_dense.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_dense.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "ZEQB91WYteaE",
        "outputId": "18ae26fc-f20b-4324-b1d7-a937bc7b62fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m38,528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,849\u001b[0m (183.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,849</span> (183.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,849\u001b[0m (183.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,849</span> (183.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 8A. TRAINING MODEL DENSE\n",
        "# ==================================================\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "\n",
        "history_dense = model_dense.fit(\n",
        "    X_train_vec, y_train,\n",
        "    validation_data=(X_val_vec, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfqw0Tjti_9",
        "outputId": "b34bb238-509c-4e9b-9673-a941aad5427c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5964 - loss: 0.6665 - val_accuracy: 0.7456 - val_loss: 0.5523\n",
            "Epoch 2/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 0.5609 - val_accuracy: 0.7512 - val_loss: 0.5341\n",
            "Epoch 3/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.5390 - val_accuracy: 0.7623 - val_loss: 0.5223\n",
            "Epoch 4/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.5261 - val_accuracy: 0.7651 - val_loss: 0.5161\n",
            "Epoch 5/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.5194 - val_accuracy: 0.7595 - val_loss: 0.5225\n",
            "Epoch 6/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7690 - loss: 0.4998 - val_accuracy: 0.7688 - val_loss: 0.5057\n",
            "Epoch 7/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7683 - loss: 0.4949 - val_accuracy: 0.7595 - val_loss: 0.5100\n",
            "Epoch 8/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7892 - loss: 0.4657 - val_accuracy: 0.7725 - val_loss: 0.5028\n",
            "Epoch 9/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.4650 - val_accuracy: 0.7707 - val_loss: 0.5069\n",
            "Epoch 10/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4572 - val_accuracy: 0.7651 - val_loss: 0.5095\n",
            "Epoch 11/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4535 - val_accuracy: 0.7679 - val_loss: 0.5070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 9A. EVALUASI TEST (DENSE)\n",
        "# ==================================================\n",
        "y_pred_prob_dense = model_dense.predict(X_test_vec)\n",
        "y_pred_dense = (y_pred_prob_dense >= 0.5).astype(int)\n",
        "\n",
        "print(\"=== Classification Report (Test, Dense) ===\")\n",
        "print(classification_report(y_test, y_pred_dense, target_names=[\"Non-sarkasme\", \"Sarkasme\"]))\n",
        "\n",
        "print(\"=== Confusion Matrix (Test, Dense) ===\")\n",
        "print(confusion_matrix(y_test, y_pred_dense))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNadiGlztm4z",
        "outputId": "41e38b57-9c9f-4a08-a0e3-a9d0aa38e116"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "=== Classification Report (Test, Dense) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-sarkasme       0.79      0.82      0.80       657\n",
            "    Sarkasme       0.69      0.65      0.67       420\n",
            "\n",
            "    accuracy                           0.75      1077\n",
            "   macro avg       0.74      0.74      0.74      1077\n",
            "weighted avg       0.75      0.75      0.75      1077\n",
            "\n",
            "=== Confusion Matrix (Test, Dense) ===\n",
            "[[536 121]\n",
            " [145 275]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text_for_prediction(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text) # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "def predict_sarcasm(text, model, d2v_model):\n",
        "    text_clean = clean_text_for_prediction(text)\n",
        "    vec = d2v_model.infer_vector(text_clean.split())\n",
        "    vec = np.expand_dims(vec, axis=0)  # (1, VECTOR_SIZE)\n",
        "    prob = model.predict(vec)[0][0]\n",
        "    label = 1 if prob >= 0.5 else 0\n",
        "    return label, prob\n",
        "\n",
        "contoh = \"Wah hebat banget, kerja segitu aja udah capek.\"\n",
        "label, prob = predict_sarcasm(contoh, model_dense, d2v_model)\n",
        "print(\"Probabilitas sarkasme:\", prob)\n",
        "print(\"Label:\", \"Sarkasme\" if label == 1 else \"Non-sarkasme\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0VslbaHtsm8",
        "outputId": "3e0659de-d210-4a11-f820-153081169bdb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Probabilitas sarkasme: 0.14970687\n",
            "Label: Non-sarkasme\n"
          ]
        }
      ]
    }
  ]
}